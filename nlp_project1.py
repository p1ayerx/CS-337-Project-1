# -*- coding: utf-8 -*-
"""NLP-project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18bHw54p5N13HrnQ9UItGDiE2qy6vOucT
"""

import nltk
from nltk import word_tokenize, pos_tag, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download
nltk.download("wordnet")
nltk.download("stopwords")
nltk.download("punkt")
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import TweetTokenizer
import spacy
from spacy.lang.en import English
import json
import pprint
import pandas as pd
import re
import sys
nlp = spacy.load("en_core_web_sm")
import numpy as np
import tweepy
from tmdbv3api import TMDb, Movie, Person, TV
from itertools import combinations 
from collections import defaultdict
import unidecode

hardcodedAwards = ['cecil b. demille award',
                   'best motion picture drama',
                   'best performance by an actress in a motion picture - drama',
                   'best performance by an actor in a motion picture - drama',
                   'best motion picture - comedy or musical',
                   'best performance by an actress in a motion picture - comedy or musical',
                   'best performance by an actor in a motion picture - comedy or musical',
                   'best animated feature film',
                   'best foreign language film',
                   'best performance by an actress in a supporting role in a motion picture',
                   'best performance by an actor in a supporting role in a motion picture',
                   'best director - motion picture',
                   'best screenplay - motion picture',
                   'best original score - motion picture',
                   'best original song - motion picture',
                   'best television series - drama',
                   'best performance by an actress in a television series - drama',
                   'best performance by an actor in a television series - drama',
                   'best television series - comedy or musical',
                   'best performance by an actress in a television series - comedy or musical',
                   'best performance by an actor in a television series - comedy or musical',
                   'best mini-series or motion picture made for television',
                   'best performance by an actress in a mini-series or motion picture made for television',
                   'best performance by an actor in a mini-series or motion picture made for television',
                   'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television',
                   'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']

# auth = tweepy.OAuthHandler(consumer_key, consumer_secret)
# auth.set_access_token(access_token, access_token_secret)
# api = tweepy.API(auth)

tmdb = TMDb()
#DONT SHARE MY API KEYYYYYYYYYYYYYYYYYYYYYYYYYYYY
tmdb.api_key = 'de18403f2add7f69d5b5a3760598be10'
tmdb.request_timeout = 3

def read(path):
  with open(path,mode="rt") as file:
    data = pd.read_json(file)

    #preprocessing takes a while so limiting to 20000 for testing
    #data = data[0:100000]

    #finds all hashtags and add to hashtag column
  data["hashtag"] = data["text"].apply(lambda x: re.findall(r"#(\w+)",x))

  #finds all mentions and add to mention column
  data["mention"] = data["text"].apply(lambda x: re.findall(r"@(\w+)",x))

  data.drop_duplicates(subset="text",inplace=True)

  data['text'] = data['text'].str.replace('[G|g]olden\\s?[G|g]lobes*', '')
  data['text'] = data['text'].str.replace('#|@|RT', '') # remove hashtags
  data['text'] = data['text'].str.replace('http\S+|www.\S+', '') # remove urls

  return data

#return preprocessed data, takes in dataframe column with the text
def preprocess_data(data):
 #Removes Numbers
 data = data.astype(str).str.replace('\d+', '')
 #lower text
 lower_text = data.str.lower()
 lemmatizer = nltk.stem.WordNetLemmatizer()
 w_tokenizer =  TweetTokenizer()
 
 def lemmatize_text(text):
  return [(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]
 
 #remove any punctuations
 def remove_punctuation(words):
   new_words = []
   for word in words:
      new_word = re.sub(r'[^\w\s]', '', (word))
      if new_word != '':
         new_words.append(new_word)
   return new_words
 
 words = lower_text.apply(lemmatize_text)
 words = words.apply(remove_punctuation)
 return pd.DataFrame(words)

#removes anything in the stop words list. Can be added by appending new words
stop_words = set(stopwords.words("english"))
def remove_stop_words_from_token(df,column_name):
  return df[column_name].apply(lambda x:[word for word in x if  word not in stop_words])

#filters tweets by regex_string ex: pic|film|movie, takes tokenized column
def filter_tweets(df,column_name, regex_string):
  temp = pd.DataFrame(df[column_name].apply(lambda x: " ".join(x)))
  return df[temp[column_name].str.contains(regex_string,regex=True)]

#obtains nouns, takes dataframe and column name with text (not token)
def get_nouns(df,column_name):
  df = df[column_name].apply(lambda x: [*nlp(x).ents])

  print(df)

  return pd.DataFrame([j.text.lower() for i in np.ravel(df) for j in i if j.text.lower() not in stop_words])

#returns freq of words, takes dataframe and column name with text (not token)
def get_freq(df,column_name):
  return df[column_name].value_counts().index.tolist()

def get_freq_vals(df, column_name):
  return df[column_name].value_counts()

def remove_dup_tweets(df, column_name):
  return df.drop_duplicates(subset=[column_name], keep='first')

def find_associated_proper_nouns(df, column_name):
  allNouns = []
  badWords = ["oscar", "nominee", "emmy", "golden", "globes", "worst", "president"]
  [badWords.append(word) for award in hardcodedAwards for word in award.replace("- ", "").split()]
  freq = defaultdict(int)

  for text in df[column_name]:
    nouns = []
    name = []
    flag = False
    words = nltk.word_tokenize(text.replace(":", ""))
    words = [word if word.lower() not in badWords else "a" for word in words]
    tagged = nltk.pos_tag(words)
    for (word, tag) in tagged:
      if tag == 'NNP' and not word.isupper():
        name.append(word)
        flag = True
      elif flag:
        strName = " ".join(name)
        nouns.append(strName)
        freq[strName] += 1
        name = []
        flag = False
    allNouns.append(nouns)
    nouns = []

  df["associated_proper_nouns"] = allNouns
  df["associated_proper_nouns"] = df["associated_proper_nouns"].apply(lambda x: [name for name in x if freq[name] > 1])
  df = df[df.astype(str)['associated_proper_nouns'] != '[]']

  sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)

  return df, sorted_freq

#takes preprocessed dataframe with tokens on column "pp_text" and text on column "text"
def find_hosts(df):
  filtered_tweets = filter_tweets(df, "pp_text", "host|hosts|hosted")
  possible_hosts, host_freq = find_associated_proper_nouns(filtered_tweets, "text")
  if host_freq[0][1] - host_freq[1][1] > 100:
    return host_freq[0][0]
  else:
    return host_freq[0][0], host_freq[1][0]

def find_best_dressed(df):
  filtered_tweets = filter_tweets(df, "pp_text", "best dressed")
  possible_best_dressed, best_dressed_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return best_dressed_freq[0][0]

def find_worst_dressed(df):
  filtered_tweets = filter_tweets(df, "pp_text", "worst dressed")
  possible_worst_dressed, worst_dressed_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return worst_dressed_freq[0][0]

def find_funniest(df):
  filtered_tweets = filter_tweets(data, "pp_text", "funniest|hilarious")
  possible_funniest, funniest_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return funniest_freq[0][0]

def find_awards(df):
  filtered_tweets = filter_tweets(df, "pp_text", "best")
  tweet_text = filtered_tweets["text"]
  award_freq_vals = get_freq_vals(tweet_text.str.extract(r'for (best [\w ,-]+) (?:for|[!#])', re.IGNORECASE).dropna(),0)
  awards = get_freq(tweet_text.str.extract(r'for (best [\w ,-]+) (?:for|[!#])', re.IGNORECASE).dropna(),0)

  filtered_awards = []
  for i, val in enumerate(award_freq_vals):
    if val > 3:
      filtered_awards.append(awards[i].lower())

  return filtered_awards

########################## MAPPING PRESENTS/NOMINEES/WINNERS TO AWARDS #####################

#COPY OF THE ASSOCIATED ACTORS FUNCTION BUT FOR MOVIES
def find_associated_movies(df, column_name):
  noun = []
  badWords = ["Oscar", "Nominee", "Emmy", "Golden", "Globes"]

  for doc in nlp.pipe(df[column_name]):
    people_and_works = []
    for token in doc:
        # if (token.ent_type_ == "PERSON" or token.ent_type_ == "WORK_OF_ART") and str(token) not in badWords:
        if token.ent_type_ == "WORK_OF_ART" and str(token) not in badWords:
          people_and_works.append(token)
    noun.append(people_and_works)

  test = []

  movies = defaultdict(int)

  for row in noun:
    combos = combinations(row, 2)
    temp = []
    for c in combos:
      name = str(c[0]) + " " + str(c[1])
      results = Movie().search(name)
      if results:
        for r in results:
          cleanName = unidecode.unidecode(r.title).replace("-", " ")
          if r.popularity > 1 and cleanName not in temp and cleanName.lower().find(name.lower()) != -1:
            temp.append(cleanName)
            movies[cleanName] += 1
    test.append(temp)

  #USE THIS TO COMPARE AGAINST OTHER REGEX SEARCHES (i.e., host vs nominee)
  sorted_freq_dict = sorted(movies.items(), key=lambda kv: kv[1], reverse=True)
            
  # df["people"] = noun
  df["associated_movies"] = test

  df = df[df['associated_movies'].map(lambda x: len(x)) > 0]

  return df, sorted_freq_dict

#COPY OF THE ASSOCIATED ACTORS FUNCTION BUT FOR TV SHOWS
def find_associated_shows(df, column_name):
  noun = []
  badWords = ["Oscar", "Nominee", "Emmy", "Golden", "Globes"]

  for doc in nlp.pipe(df[column_name]):
    people_and_works = []
    for token in doc:
        # if (token.ent_type_ == "PERSON" or token.ent_type_ == "WORK_OF_ART") and str(token) not in badWords:
        if token.ent_type_ == "WORK_OF_ART" and str(token) not in badWords:
          people_and_works.append(token)
    noun.append(people_and_works)

  test = []

  shows = defaultdict(int)

  for row in noun:
    combos = combinations(row, 2)
    temp = []
    for c in combos:
      name = str(c[0]) + " " + str(c[1])
      results = TV().search(name)
      if results:
        for r in results:
          cleanName = unidecode.unidecode(r.name).replace("-", " ")
          if r.popularity > 1 and cleanName not in temp and cleanName.lower().find(name.lower()) != -1:
            temp.append(cleanName)
            shows[cleanName] += 1
    test.append(temp)

  #USE THIS TO COMPARE AGAINST OTHER REGEX SEARCHES (i.e., host vs nominee)
  sorted_freq_dict = sorted(shows.items(), key=lambda kv: kv[1], reverse=True)
            
  # df["people"] = noun
  df["associated_shows"] = test

  df = df[df['associated_shows'].map(lambda x: len(x)) > 0]

  return df, sorted_freq_dict

def find_presenters(award, tweets):
  possible_presenters, present_freq = find_associated_actors(tweets, "text")
  return possible_presenters[["text", "associated_actors"]], present_freq

def find_nominees(award, tweets):
  # DO ANOTHER FILTER BY REGEX FOR NOMINEE|NOMINEES
  nominee_freq = defaultdict(int)
  if "cecille" in award or "actor" in award or "actress" in award or "director" in award:
    # search find_associated_actors
    possible_nominees, nominee_freq = find_associated_actors(tweets, "text")
    return possible_nominees[["text", "associated_actors"]], nominee_freq
  else:
    if "television" in award:
      # search find_associated_shows
      possible_nominees, nominee_freq = find_associated_shows(tweets, "text")
      return possible_nominees[["text", "associated_shows"]], nominee_freq

    # search find_associated_movies
    possible_nominees, nominee_freq = find_associated_movies(tweets, "text")
    return possible_nominees[["text", "associated_movies"]], nominee_freq

def find_winners(award, tweets):
  winner_freq = defaultdict(int)
  if "cecil" in award or "actor" in award or "actress" in award or "director" in award:
    # search find_associated_actors
    possible_winners, winners_freq = find_associated_actors(tweets, "text")
    return possible_winners[["text", "associated_actors"]], winners_freq
  else:
    if "television" in award:
      # search find_associated_shows
      possible_winners, winner_freq = find_associated_shows(tweets, "text")
      return possible_winners[["text", "associated_shows"]], winner_freq

    # search find_associated_movies
    possible_winners, winners_freq = find_associated_actors(tweets, "text")
    return possible_winners[["text", "associated_movies"]], winners_freq

def get_filtered_award_tweets(df, award):
  regex_str = ''

  if 'picture' in award or 'film' in award:
    regex_str = 'pic|movie|film'

    # if filtered_subsets['picture'] == None:
    filtered_subsets['picture'] = filter_tweets(df, "pp_text", regex_str)

    # person_filter = filter_tweets_by_person(filtered_subsets['picture'], award)
    # attribute_filter = filter_tweets_by_attribute(person_filter, award)
    filtered_tweets = filter_tweets(filtered_subsets['picture'], "pp_text", format_regex_str(award))
    return filtered_tweets

  elif 'television' in award:
    regex_str = 'television|series|show|hbo|netflix|hulu|tv'

    # if filtered_subsets['television'] == None:
    filtered_subsets['television'] = filter_tweets(df, "pp_text", regex_str)

    # person_filter = filter_tweets_by_person(filtered_subsets['picture'], award)
    # attribute_filter = filter_tweets_by_tv_attribute(person_filter, award)
    filtered_tweets = filter_tweets(filtered_subsets['television'], "pp_text", format_regex_str(award))
    return filtered_tweets
  else:
    return df

def format_regex_str(award):
  regex_str = ''

  filtered_award = award

  stop_words = ['by', 'an', 'in', 'a', 'or', 'made', 'for']

  for w in stop_words:
    filtered_award = filtered_award.replace(w, '')

  filtered_award = filtered_award.replace('-', '')

  blocked_phrases = ['motion picture', 'best performance', 'animated feature', 'foreign language', 'best director', 'best screenplay', 'original score', 'original song', 'television series']

  for phrase in blocked_phrases:
    words = phrase.split(' ', 1)
    formatted_regex = ''
    for word in words:
      formatted_regex = formatted_regex + word + '&'

    formatted_regex = formatted_regex[:-1]

    filtered_award = filtered_award.replace(phrase, formatted_regex)

  filtered_award = filtered_award.replace(' ', '|')

  return filtered_award

def process_award(df):
  presenters_nominees_winners = {}

  # for award in hardcodedAwards:
  award = hardcodedAwards[1]
  # get a subset of tweets based on whether the award is for movies or tv
  filtered_tweets = get_filtered_award_tweets(data, award)

  presenters = find_presenters(award, filtered_tweets)
  nominees = find_nominees(award, filtered_tweets)
  winners = find_winners(award, filtered_tweets)
  presenters_nominees_winners[award] = {"Presenters": presenters, "Nominees": nominees, "Winners": winners}

  return presenters_nominees_winners

def output(data):
  hosts = find_hosts(data)
  presenters_nominees_winners = process_award(data)
  presenters_nominees_winners["Host"] = hosts
  best_dressed = find_best_dressed(data)
  worst_dressed = find_worst_dressed(data)
  for key in presenters_nominees_winnters:
    print (key, presenters_nominees_winners[key])
  print ("Best Dressed: " + best_dressed)
  print ("Worst Dressed: " + worst_dressed)
  print ("Funniest: " + find_funniest)
  return presenters_nominees_winners
