# -*- coding: utf-8 -*-
"""NLP-project1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18bHw54p5N13HrnQ9UItGDiE2qy6vOucT
"""

import nltk
from nltk import word_tokenize, pos_tag, sent_tokenize
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
nltk.download
nltk.download("wordnet")
nltk.download("stopwords")
nltk.download("punkt")
nltk.download('averaged_perceptron_tagger')
from nltk.tokenize import TweetTokenizer
import spacy
from spacy.lang.en import English
import json
import pprint
import pandas as pd
import re
import sys
nlp = spacy.load("en_core_web_sm")
import numpy as np
from itertools import combinations 
from collections import defaultdict

hardcodedAwards = ['cecil b. demille award',
                   'best motion picture drama',
                   'best performance by an actress in a motion picture - drama',
                   'best performance by an actor in a motion picture - drama',
                   'best motion picture - comedy or musical',
                   'best performance by an actress in a motion picture - comedy or musical',
                   'best performance by an actor in a motion picture - comedy or musical',
                   'best animated feature film',
                   'best foreign language film',
                   'best performance by an actress in a supporting role in a motion picture',
                   'best performance by an actor in a supporting role in a motion picture',
                   'best director - motion picture',
                   'best screenplay - motion picture',
                   'best original score - motion picture',
                   'best original song - motion picture',
                   'best television series - drama',
                   'best performance by an actress in a television series - drama',
                   'best performance by an actor in a television series - drama',
                   'best television series - comedy or musical',
                   'best performance by an actress in a television series - comedy or musical',
                   'best performance by an actor in a television series - comedy or musical',
                   'best mini-series or motion picture made for television',
                   'best performance by an actress in a mini-series or motion picture made for television',
                   'best performance by an actor in a mini-series or motion picture made for television',
                   'best performance by an actress in a supporting role in a series, mini-series or motion picture made for television',
                   'best performance by an actor in a supporting role in a series, mini-series or motion picture made for television']

def read(path):
  with open(path,mode="rt") as file:
    data = pd.read_json(file)

    #preprocessing takes a while so limiting to 20000 for testing
    #data = data[0:100000]

    #finds all hashtags and add to hashtag column
  data["hashtag"] = data["text"].apply(lambda x: re.findall(r"#(\w+)",x))

  #finds all mentions and add to mention column
  data["mention"] = data["text"].apply(lambda x: re.findall(r"@(\w+)",x))

  data.drop_duplicates(subset="text",inplace=True)

  data['text'] = data['text'].str.replace('[G|g]olden\\s?[G|g]lobes*', '')
  data['text'] = data['text'].str.replace('#|@|RT', '') # remove hashtags
  data['text'] = data['text'].str.replace('http\S+|www.\S+', '') # remove urls

  return data

#return preprocessed data, takes in dataframe column with the text
def preprocess_data(data):
 #Removes Numbers
 data = data.astype(str).str.replace('\d+', '')
 #lower text
 lower_text = data.str.lower()
 lemmatizer = nltk.stem.WordNetLemmatizer()
 w_tokenizer =  TweetTokenizer()
 
 def lemmatize_text(text):
  return [(lemmatizer.lemmatize(w)) for w in w_tokenizer.tokenize((text))]
 
 #remove any punctuations
 def remove_punctuation(words):
   new_words = []
   for word in words:
      new_word = re.sub(r'[^\w\s]', '', (word))
      if new_word != '':
         new_words.append(new_word)
   return new_words
 
 words = lower_text.apply(lemmatize_text)
 words = words.apply(remove_punctuation)
 return pd.DataFrame(words)

#removes anything in the stop words list. Can be added by appending new words
stop_words = set(stopwords.words("english"))
def remove_stop_words_from_token(df,column_name):
  return df[column_name].apply(lambda x:[word for word in x if  word not in stop_words])

#filters tweets by regex_string ex: pic|film|movie, takes tokenized column
def filter_tweets(df,column_name, regex_string):
  temp = pd.DataFrame(df[column_name].apply(lambda x: " ".join(x)))
  return df[temp[column_name].str.contains(regex_string,regex=True)]

#obtains nouns, takes dataframe and column name with text (not token)
def get_nouns(df,column_name):
  df = df[column_name].apply(lambda x: [*nlp(x).ents])

  print(df)

  return pd.DataFrame([j.text.lower() for i in np.ravel(df) for j in i if j.text.lower() not in stop_words])

#returns freq of words, takes dataframe and column name with text (not token)
def get_freq(df,column_name):
  return df[column_name].value_counts().index.tolist()

def get_freq_vals(df, column_name):
  return df[column_name].value_counts()

def remove_dup_tweets(df, column_name):
  return df.drop_duplicates(subset=[column_name], keep='first')

def find_associated_proper_nouns(df, column_name):
  allNouns = []
  badWords = ["oscar", "nominee", "emmy", "golden", "globes", "worst", "president"]
  [badWords.append(word) for award in hardcodedAwards for word in award.replace("- ", "").split()]
  freq = defaultdict(int)

  for text in df[column_name]:
    nouns = []
    name = []
    flag = False
    words = nltk.word_tokenize(text.replace(":", ""))
    words = [word if word.lower() not in badWords else "a" for word in words]
    tagged = nltk.pos_tag(words)
    for (word, tag) in tagged:
      if tag == 'NNP' and not word.isupper():
        name.append(word)
        flag = True
      elif flag:
        strName = " ".join(name)
        nouns.append(strName)
        freq[strName] += 1
        name = []
        flag = False
    allNouns.append(nouns)
    nouns = []

  df["associated_proper_nouns"] = allNouns
  df["associated_proper_nouns"] = df["associated_proper_nouns"].apply(lambda x: [name for name in x if freq[name] > 1])
  df = df[df.astype(str)['associated_proper_nouns'] != '[]']

  sorted_freq = sorted(freq.items(), key=lambda kv: kv[1], reverse=True)

  return df, sorted_freq

#takes preprocessed dataframe with tokens on column "pp_text" and text on column "text"
def find_hosts(df):
  filtered_tweets = filter_tweets(df, "pp_text", "host|hosts|hosted")
  possible_hosts, host_freq = find_associated_proper_nouns(filtered_tweets, "text")
  if host_freq[0][1] - host_freq[1][1] > 100:
    return host_freq[0][0]
  else:
    return host_freq[0][0], host_freq[1][0]

def find_best_dressed(df):
  filtered_tweets = filter_tweets(df, "pp_text", "best dressed")
  possible_best_dressed, best_dressed_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return best_dressed_freq[0][0]

def find_worst_dressed(df):
  filtered_tweets = filter_tweets(df, "pp_text", "worst dressed")
  possible_worst_dressed, worst_dressed_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return worst_dressed_freq[0][0]

def find_funniest(df):
  filtered_tweets = filter_tweets(df, "pp_text", "funniest|hilarious")
  possible_funniest, funniest_freq = find_associated_proper_nouns(filtered_tweets, "text")
  return funniest_freq[0][0]

def find_awards(df):
  filtered_tweets = filter_tweets(df, "pp_text", "best")
  tweet_text = filtered_tweets["text"]
  award_freq_vals = get_freq_vals(tweet_text.str.extract(r'for (best [\w ,-]+) (?:for|[!#])', re.IGNORECASE).dropna(),0)
  awards = get_freq(tweet_text.str.extract(r'for (best [\w ,-]+) (?:for|[!#])', re.IGNORECASE).dropna(),0)

  filtered_awards = []
  for i, val in enumerate(award_freq_vals):
    if val > 3:
      filtered_awards.append(awards[i].lower())

  return filtered_awards

########################## MAPPING PRESENTS/NOMINEES/WINNERS TO AWARDS #####################


def find_presenters(possible_presenters, presenter_freq, possible_awards, award_freq, award):
  presenters = possible_presenters["associated_proper_nouns"].tolist()
  presenter_list = []
  for award in award_freq:
    name = award[0]
    if [name] in presenters:
      presenter_list.append(name)
      return presenter_list

  return presenter_list

def find_nominees(possible_nominees, nominee_freq, possible_awards, award_freq, award):
  nominees = possible_nominees["associated_proper_nouns"].tolist()
  nominee_list = []
  counter = 0
  for award in award_freq:
    name = award[0]
    if [name] in nominees:
      counter += 1
      nominee_list.append(name)

      if counter == 5:
        return nominee_list

  return nominee_list

def format_regex_str(award):
  filtered_award = award

  words = filtered_award.split(' ')

  formatted_regex = ''
  for w in words:
    formatted_regex = formatted_regex + '(?=.*' + w + ')'

  filtered_award = formatted_regex  

  stop_words = ['(?=.*by)', '(?=.*an)', '(?=.*in)', '(?=.*a)', '(?=.*or)', '(?=.*made)', '(?=.*for)', '(?=.*b.)']

  for w in stop_words:
    filtered_award = filtered_award.replace(w, '')

  filtered_award = filtered_award.replace('-', '')

  return filtered_award

def process_award(df, awards):
  presenters_nominees_winners = {}

  presenter_tweets = filter_tweets(df, "pp_text", "present|presenter|presents|presented|presenters")
  nominee_tweets = filter_tweets(df, "pp_text", "nomination|nominee|nominated|nominate|snubbed|snub")
  winner_tweets = filter_tweets(df, "pp_text", "win|wins|winner|winners|won")

  possible_presenters, presenter_freq = find_associated_proper_nouns(presenter_tweets, "text")
  possible_nominees, nominee_freq = find_associated_proper_nouns(nominee_tweets, "text")
  possible_winners, winner_freq = find_associated_proper_nouns(winner_tweets, "text")

  for award in awards:
    award_tweets = filter_tweets(df, "pp_text", format_regex_str(award))
    possible_awards, award_freq = find_associated_proper_nouns(award_tweets, "text")

    presenters = find_presenters(possible_presenters, presenter_freq, possible_awards, award_freq, awards)
    nominees = find_nominees(possible_nominees, nominee_freq, possible_awards, award_freq, awards)

    winners = ""
    if len(award_freq) > 0:
      winners = award_freq[0][0]

    presenters_nominees_winners[award] = {"Presenters": presenters, "Nominees": nominees, "Winners": winners}

  return presenters_nominees_winners

def output(data, awardz):
  hosts = find_hosts(data)
  presenters_nominees_winners = process_award(data, awardz)
  presenters_nominees_winners["Host"] = hosts
  best_dressed = find_best_dressed(data)
  worst_dressed = find_worst_dressed(data)
  funniest = find_funniest(data)
  for key in presenters_nominees_winners:
    print(key, presenters_nominees_winners[key])
  print("Best Dressed: " + best_dressed)
  print("Worst Dressed: " + worst_dressed)
  print("Funniest: " + funniest)
  return presenters_nominees_winners